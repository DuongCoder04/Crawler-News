# üïê Scheduler Mode - H∆∞·ªõng D·∫´n S·ª≠ D·ª•ng

## üéØ T·ªïng Quan

Scheduler mode cho ph√©p crawler t·ª± ƒë·ªông ch·∫°y theo l·ªãch m√† kh√¥ng c·∫ßn can thi·ªáp th·ªß c√¥ng. Crawler s·∫Ω:
- ‚úÖ Ch·∫°y initial crawl ngay khi kh·ªüi ƒë·ªông
- ‚úÖ T·ª± ƒë·ªông crawl theo l·ªãch ƒë√£ c·∫•u h√¨nh
- ‚úÖ Ch·∫°y li√™n t·ª•c cho ƒë·∫øn khi b·∫°n d·ª´ng l·∫°i

---

## üöÄ C√°ch Kh·ªüi ƒê·ªông

### Linux/Mac

```bash
cd Crawler
./start_crawler.sh
```

### Windows

```cmd
cd Crawler
start_crawler.bat
```

### Manual

```bash
cd Crawler
python main.py --mode scheduler
```

---

## ‚öôÔ∏è C·∫•u H√¨nh L·ªãch Crawl

M·ªói domain c√≥ l·ªãch ri√™ng trong file config. V√≠ d·ª• `config/domains/vnexpress.json`:

```json
{
    "schedule": {
        "cron": "0 */2 * * *",
        "description": "Ch·∫°y m·ªói 2 gi·ªù"
    }
}
```

### Cron Format

```
minute hour day month weekday
```

### V√≠ D·ª•

| Cron | M√¥ T·∫£ |
|------|-------|
| `0 */2 * * *` | M·ªói 2 gi·ªù |
| `0 */3 * * *` | M·ªói 3 gi·ªù |
| `0 */4 * * *` | M·ªói 4 gi·ªù |
| `0 * * * *` | M·ªói gi·ªù |
| `0 8 * * *` | H√†ng ng√†y l√∫c 8:00 |
| `0 0 * * *` | H√†ng ng√†y l√∫c 00:00 |

---

## üìä L·ªãch Hi·ªán T·∫°i

| Domain | Schedule | Status |
|--------|----------|--------|
| VnExpress | M·ªói 2 gi·ªù | ‚úÖ Enabled |
| Coin68 | M·ªói 3 gi·ªù | ‚ö†Ô∏è Disabled (robots.txt) |
| T·∫°p Ch√≠ Bitcoin | M·ªói 3 gi·ªù | ‚ö†Ô∏è Disabled (robots.txt) |
| Cointelegraph VN | M·ªói 4 gi·ªù | ‚ö†Ô∏è Disabled (robots.txt) |
| Genk | M·ªói 2 gi·ªù | ‚ö†Ô∏è Disabled (404) |
| ICTNews | M·ªói 2 gi·ªù | ‚ö†Ô∏è Disabled (selector issue) |

**Hi·ªán t·∫°i ch·ªâ VnExpress ƒëang active.**

---

## üìù Log Output

Khi ch·∫°y scheduler, b·∫°n s·∫Ω th·∫•y:

```
============================================================
X-Wise News Crawler System
============================================================
Running crawler in scheduler mode
Crawler will run automatically based on schedule configuration
Press Ctrl+C to stop

Loaded config: VnExpress
Connected to database: wise_local@127.0.0.1

Scheduled VnExpress: Every 2 hours - Ch·∫°y m·ªói 2 gi·ªù

============================================================
Running initial crawl for all domains...
============================================================

Crawling VnExpress...
Successfully extracted: Article Title...
Created news: uuid - Article Title...

============================================================
Scheduler started. Waiting for next scheduled run...
============================================================
```

---

## üõë D·ª´ng Crawler

Nh·∫•n `Ctrl+C` ƒë·ªÉ d·ª´ng scheduler:

```
^C
Crawler stopped by user
```

---

## üîß Enable/Disable Domains

ƒê·ªÉ enable/disable m·ªôt domain, edit file config:

```json
{
    "domain": "vnexpress.net",
    "name": "VnExpress",
    "enabled": true,  // false ƒë·ªÉ disable
    ...
}
```

---

## üìä Monitor Crawler

### Check Logs

```bash
# Real-time logs
tail -f logs/crawler.log

# Last 100 lines
tail -100 logs/crawler.log
```

### Check Database

```bash
cd ../wise-cms-backend
node test-db-connection.js
```

### Check Redis Cache

```bash
redis-cli
> KEYS crawler:article:*
> DBSIZE
```

---

## üêõ Troubleshooting

### Scheduler Kh√¥ng Ch·∫°y

**Ki·ªÉm tra:**
1. Database connection OK?
2. Redis connection OK?
3. Domain configs c√≥ l·ªói kh√¥ng?

```bash
python test_setup.py
```

### Kh√¥ng Crawl ƒê∆∞·ª£c B√†i M·ªõi

**Nguy√™n nh√¢n:**
- B√†i ƒë√£ ƒë∆∞·ª£c crawl (duplicate detection)
- Selector kh√¥ng ƒë√∫ng
- Website thay ƒë·ªïi c·∫•u tr√∫c

**Gi·∫£i ph√°p:**
```bash
# Check logs
tail -f logs/crawler.log

# Test crawl th·ªß c√¥ng
python main.py --mode once --domain vnexpress.net
```

### Memory/CPU Cao

**Gi·∫£i ph√°p:**
- Gi·∫£m s·ªë l∆∞·ª£ng domains active
- TƒÉng delay gi·ªØa c√°c requests
- Gi·∫£m `MAX_ARTICLES_PER_CATEGORY` trong `.env`

---

## üí° Best Practices

### 1. Ch·∫°y Trong Screen/Tmux

```bash
# Start screen session
screen -S crawler

# Run crawler
cd Crawler
./start_crawler.sh

# Detach: Ctrl+A, D
# Reattach: screen -r crawler
```

### 2. Ch·∫°y Nh∆∞ Service (Systemd)

T·∫°o file `/etc/systemd/system/xwise-crawler.service`:

```ini
[Unit]
Description=X-Wise News Crawler
After=network.target postgresql.service redis.service

[Service]
Type=simple
User=your-user
WorkingDirectory=/path/to/Crawler
ExecStart=/path/to/Crawler/venv/bin/python main.py --mode scheduler
Restart=always
RestartSec=10

[Install]
WantedBy=multi-user.target
```

Enable v√† start:
```bash
sudo systemctl enable xwise-crawler
sudo systemctl start xwise-crawler
sudo systemctl status xwise-crawler
```

### 3. Monitor v·ªõi Logs

```bash
# Rotate logs t·ª± ƒë·ªông (ƒë√£ config trong logger)
# Max size: 10MB
# Retention: 30 days
```

---

## üìà Performance Tips

### 1. ƒêi·ªÅu Ch·ªânh Rate Limit

File `.env`:
```env
RATE_LIMIT_VNEXPRESS=30  # requests/minute
CRAWLER_TIMEOUT=30       # seconds
CRAWLER_MAX_RETRIES=3
```

### 2. Gi·ªõi H·∫°n Articles

```env
MAX_ARTICLES_PER_CATEGORY=50  # Gi·∫£m xu·ªëng n·∫øu c·∫ßn
```

### 3. Redis Memory

```bash
# Check Redis memory
redis-cli INFO memory

# Clear old cache n·∫øu c·∫ßn
redis-cli FLUSHDB
```

---

## ‚úÖ Checklist Tr∆∞·ªõc Khi Ch·∫°y Production

- [ ] Database connection OK
- [ ] Redis connection OK
- [ ] Test crawl th√†nh c√¥ng
- [ ] Logs directory exists
- [ ] Disk space ƒë·ªß
- [ ] Monitor setup (optional)
- [ ] Backup database
- [ ] Document l·ªãch crawl

---

**Status:** ‚úÖ READY TO USE  
**Recommendation:** Ch·∫°y trong screen/tmux ho·∫∑c systemd service  
**Last Updated:** 10/02/2026
